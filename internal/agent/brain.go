package agent

import (
	"fmt"
	"strings"

	"github.com/BlakeLiAFK/kele/internal/llm"
	"github.com/BlakeLiAFK/kele/internal/memory"
	"github.com/BlakeLiAFK/kele/internal/tools"
)

// Brain AI å¤§è„‘
type Brain struct {
	llmClient *llm.Client
	executor  *tools.Executor
	memory    *memory.Store
	history   []llm.Message
	maxTurns  int
}

// NewBrain åˆ›å»ºæ–°å¤§è„‘
func NewBrain() *Brain {
	return &Brain{
		llmClient: llm.NewClient(),
		executor:  tools.NewExecutor(),
		memory:    memory.NewStore(),
		history:   []llm.Message{},
		maxTurns:  20, // ä¿ç•™æœ€è¿‘ 20 è½®å¯¹è¯
	}
}

// Chat å¤„ç†å¯¹è¯ï¼ˆéæµå¼ï¼‰
func (b *Brain) Chat(userInput string) (string, error) {
	// æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
	b.addMessage("user", userInput)

	// è°ƒç”¨ LLM
	resp, err := b.llmClient.Chat(b.getMessages(), b.executor.GetTools())
	if err != nil {
		return "", err
	}

	if len(resp.Choices) == 0 {
		return "", fmt.Errorf("API è¿”å›ç©ºå“åº”")
	}

	choice := resp.Choices[0]

	// å¤„ç†å·¥å…·è°ƒç”¨
	if len(choice.ToolCalls) > 0 {
		return b.handleToolCalls(choice.ToolCalls)
	}

	// æ·»åŠ åŠ©æ‰‹å“åº”
	b.addMessage("assistant", choice.Message.Content)

	// ä¿å­˜åˆ°å†…å­˜
	b.memory.SaveMessage("user", userInput)
	b.memory.SaveMessage("assistant", choice.Message.Content)

	return choice.Message.Content, nil
}

// ChatStream æµå¼å¯¹è¯
func (b *Brain) ChatStream(userInput string) (<-chan StreamEvent, error) {
	eventChan := make(chan StreamEvent, 100)

	go func() {
		defer close(eventChan)

		// æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
		b.addMessage("user", userInput)

		// è·å–æµå¼å“åº”
		contentChan, errChan := b.llmClient.ChatStream(b.getMessages(), b.executor.GetTools())

		fullContent := ""
		for {
			select {
			case content, ok := <-contentChan:
				if !ok {
					// æµç»“æŸ
					b.addMessage("assistant", fullContent)
					b.memory.SaveMessage("user", userInput)
					b.memory.SaveMessage("assistant", fullContent)
					return
				}
				fullContent += content
				eventChan <- StreamEvent{
					Type:    "content",
					Content: content,
				}

			case err := <-errChan:
				if err != nil {
					eventChan <- StreamEvent{
						Type:  "error",
						Error: err.Error(),
					}
					return
				}
			}
		}
	}()

	return eventChan, nil
}

// handleToolCalls å¤„ç†å·¥å…·è°ƒç”¨
func (b *Brain) handleToolCalls(toolCalls []llm.ToolCall) (string, error) {
	var results []string

	for _, tc := range toolCalls {
		// æ‰§è¡Œå·¥å…·
		result, err := b.executor.Execute(tc)
		if err != nil {
			result = fmt.Sprintf("é”™è¯¯: %v", err)
		}

		results = append(results, fmt.Sprintf("ğŸ”§ %s:\n%s", tc.Function.Name, result))

		// æ·»åŠ å·¥å…·è°ƒç”¨åˆ°å†å²
		b.addMessage("assistant", fmt.Sprintf("ä½¿ç”¨å·¥å…·: %s", tc.Function.Name))
		b.addMessage("tool", result)
	}

	// å†æ¬¡è°ƒç”¨ LLM è·å–æœ€ç»ˆå“åº”
	resp, err := b.llmClient.Chat(b.getMessages(), nil)
	if err != nil {
		return strings.Join(results, "\n\n"), nil
	}

	if len(resp.Choices) > 0 {
		finalResponse := resp.Choices[0].Message.Content
		b.addMessage("assistant", finalResponse)

		// ä¿å­˜åˆ°å†…å­˜
		b.memory.SaveMessage("assistant", finalResponse)

		return strings.Join(results, "\n\n") + "\n\n" + finalResponse, nil
	}

	return strings.Join(results, "\n\n"), nil
}

// addMessage æ·»åŠ æ¶ˆæ¯åˆ°å†å²
func (b *Brain) addMessage(role, content string) {
	b.history = append(b.history, llm.Message{
		Role:    role,
		Content: content,
	})

	// é™åˆ¶å†å²é•¿åº¦
	if len(b.history) > b.maxTurns*2 {
		b.history = b.history[len(b.history)-b.maxTurns*2:]
	}
}

// getMessages è·å–å¯¹è¯å†å²ï¼ˆæ·»åŠ ç³»ç»Ÿæç¤ºï¼‰
func (b *Brain) getMessages() []llm.Message {
	systemPrompt := llm.Message{
		Role: "system",
		Content: `ä½ æ˜¯ Keleï¼Œä¸€ä¸ªæ™ºèƒ½çš„ç»ˆç«¯ AI åŠ©æ‰‹ã€‚ä½ å¯ä»¥ï¼š
1. å›ç­”é—®é¢˜å’Œè¿›è¡Œå¯¹è¯
2. ä½¿ç”¨å·¥å…·æ‰§è¡Œæ“ä½œï¼š
   - bash: æ‰§è¡Œå‘½ä»¤
   - read: è¯»å–æ–‡ä»¶
   - write: åˆ›å»ºæˆ–ä¿®æ”¹æ–‡ä»¶

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä¿æŒç®€æ´ä¸“ä¸šã€‚å½“éœ€è¦æ‰§è¡Œæ“ä½œæ—¶ï¼Œä¸»åŠ¨ä½¿ç”¨å·¥å…·ã€‚`,
	}

	messages := []llm.Message{systemPrompt}
	messages = append(messages, b.history...)
	return messages
}

// GetHistory è·å–å†å²è®°å½•
func (b *Brain) GetHistory() []llm.Message {
	return b.history
}

// ClearHistory æ¸…ç©ºå†å²
func (b *Brain) ClearHistory() {
	b.history = []llm.Message{}
}

// StreamEvent æµå¼äº‹ä»¶
type StreamEvent struct {
	Type    string // content, tool, error, done
	Content string
	Tool    *ToolExecution
	Error   string
}

// ToolExecution å·¥å…·æ‰§è¡Œä¿¡æ¯
type ToolExecution struct {
	Name   string
	Args   map[string]interface{}
	Result string
}

// SaveMemory ä¿å­˜è®°å¿†
func (b *Brain) SaveMemory(key, value string) error {
	return b.memory.UpdateMemory(key, value)
}

// SearchMemory æœç´¢è®°å¿†
func (b *Brain) SearchMemory(query string) ([]string, error) {
	return b.memory.Search(query, 5)
}

// SetModel è®¾ç½®æ¨¡å‹
func (b *Brain) SetModel(model string) {
	b.llmClient.SetModel(model)
}

// GetModel è·å–å½“å‰æ¨¡å‹
func (b *Brain) GetModel() string {
	return b.llmClient.GetModel()
}

// GetDefaultModel è·å–é»˜è®¤æ¨¡å‹
func (b *Brain) GetDefaultModel() string {
	return b.llmClient.GetDefaultModel()
}

// ResetModel é‡ç½®ä¸ºé»˜è®¤æ¨¡å‹
func (b *Brain) ResetModel() {
	b.llmClient.ResetModel()
}
